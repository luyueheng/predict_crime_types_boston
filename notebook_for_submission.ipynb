{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Crimes in Boston\n",
    "\n",
    "### CS109A Final Project\n",
    "\n",
    "Semester: Fall 2019\n",
    "\n",
    "Student: Ethan Kim, Yueheng Lu, Jimmy Qin, Jack Wongtam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "### cs109default ### \n",
    "import random\n",
    "random.seed(112358)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from random import randint \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import tree\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "### cs109default ### \n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)  # You should see a 2.0.0 here!\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-testing for difference in means between streelight distances: night versus day\n",
    "\n",
    "is_night = []\n",
    "for i in range(design.shape[0]):\n",
    "    if (0 <= df['HOUR'].values[i] <= 6 or 20 <= df['HOUR'].values[i] <= 23):\n",
    "        is_night.append(1)\n",
    "    else:\n",
    "        is_night.append(0)\n",
    "\n",
    "df['is_night'] = is_night\n",
    "\n",
    "crimes_day = df[design.df == 0]\n",
    "crimes_night = df[design.df == 1]\n",
    "\n",
    "#Deaths\n",
    "deaths_day = crimes_day[crimes_day.Offense_category == \"Drugs\"]\n",
    "deaths_night = crimes_night[crimes_night.Offense_category == \"Drugs\"]\n",
    "print(scipy.stats.ttest_ind(deaths_day[\"log_dist_lights\"], deaths_night[\"log_dist_lights\"]))\n",
    "\n",
    "#Drugs\n",
    "drugs_day = crimes_day[crimes_day.Offense_category == \"Drugs\"]\n",
    "drugs_night = crimes_night[crimes_night.Offense_category == \"Drugs\"]\n",
    "print(scipy.stats.ttest_ind(drugs_day[\"log_dist_lights\"], drugs_night[\"log_dist_lights\"]))\n",
    "\n",
    "#Property\n",
    "property_day = crimes_day[crimes_day.Offense_category == \"Property\"]\n",
    "property_night = crimes_night[crimes_night.Offense_category == \"Property\"]\n",
    "print(scipy.stats.ttest_ind(property_day[\"log_dist_lights\"], property_night[\"log_dist_lights\"]))\n",
    "\n",
    "#Public\n",
    "public_day = crimes_day[crimes_day.Offense_category == \"Public\"]\n",
    "public_night = crimes_night[crimes_night.Offense_category == \"Public\"]\n",
    "print(scipy.stats.ttest_ind(public_day[\"log_dist_lights\"], public_night[\"log_dist_lights\"]))\n",
    "\n",
    "#Private\n",
    "private_day = crimes_day[crimes_day.Offense_category == \"Private\"]\n",
    "private_night = crimes_night[crimes_night.Offense_category == \"Private\"]\n",
    "print(scipy.stats.ttest_ind(private_day[\"log_dist_lights\"], private_night[\"log_dist_lights\"]))\n",
    "\n",
    "#Force\n",
    "force_day = crimes_day[crimes_day.Offense_category == \"Force\"]\n",
    "force_night = crimes_night[crimes_night.Offense_category == \"Force\"]\n",
    "print(scipy.stats.ttest_ind(force_day[\"log_dist_lights\"], force_night[\"log_dist_lights\"]))\n",
    "\n",
    "#Money\n",
    "money_day = crimes_day[crimes_day.Offense_category == \"Money\"]\n",
    "money_night = crimes_night[crimes_night.Offense_category == \"Money\"]\n",
    "print(scipy.stats.ttest_ind(money_day[\"log_dist_lights\"], money_night[\"log_dist_lights\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression on \"deep night\", which is the absolute value of the difference between hour and 2 pm,\n",
    "#log-transformed distance to the nearest streetlight, and their interaction.\n",
    "\n",
    "df[\"deep_night\"] = np.abs(df[\"HOUR\"] - 14)\n",
    "df[\"log_dist_lights_times_deep_night\"] = df[\"deep_night\"] * df[\"log_dist_stl\"]\n",
    "df = pd.get_dummies(df, columns = [\"Offense_category\"])\n",
    "\n",
    "X = df[[\"log_dist_lights\", \"deep_night\", \"log_dist_lights_times_deep_night\"]]\n",
    "\n",
    "#Deaths\n",
    "logit_model1 = sm.Logit(df[\"Offense_category_Death\"], X)\n",
    "result1 = logit_model1.fit()\n",
    "print(result1.summary())\n",
    "\n",
    "#Drugs\n",
    "logit_model2 = sm.Logit(df[\"Offense_category_Drugs\"], X)\n",
    "result2 = logit_model2.fit()\n",
    "print(result2.summary())\n",
    "\n",
    "#Property\n",
    "logit_model3 = sm.Logit(df[\"Offense_category_Property\"], X)\n",
    "result3 = logit_model3.fit()\n",
    "print(result3.summary())\n",
    "\n",
    "#Public\n",
    "logit_model4 = sm.Logit(df[\"Offense_category_Public\"], X)\n",
    "result4 = logit_model4.fit()\n",
    "print(result4.summary())\n",
    "\n",
    "#Private\n",
    "logit_model5 = sm.Logit(df[\"Offense_category_Private\"], X)\n",
    "result5 = logit_model5.fit()\n",
    "print(result5.summary())\n",
    "\n",
    "#Force\n",
    "logit_model6 = sm.Logit(df[\"Offense_category_Force\"], X)\n",
    "result6 = logit_model6.fit()\n",
    "print(result6.summary())\n",
    "\n",
    "#Money\n",
    "logit_model7 = sm.Logit(df[\"Offense_category_Money\"], X)\n",
    "result7 = logit_model7.fit()\n",
    "print(result7.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multilinear regression using crime types to predict inequality metrics\n",
    "\n",
    "df = pd.get_dummies(df, columns = [\"Offense_category\"])\n",
    "df_crimes = df[[\"Offense_category_Death\", \"Offense_category_Drugs\", \"Offense_category_Force\", \"Offense_category_Money\", \"Offense_category_Private\", \"Offense_category_Public\"]]\n",
    "X = df_crimes.values\n",
    "\n",
    "model1 = sm.OLS(df[\"gini\"].values, X).fit()\n",
    "model1.summary()\n",
    "\n",
    "model2 = sm.OLS(df[\"%High_Income_HH\"].values, X).fit()\n",
    "model2.summary()\n",
    "\n",
    "model3 = sm.OLS(df[\"%Low_Edu\"].values, X).fit()\n",
    "model3.summary()\n",
    "\n",
    "model4 = sm.OLS(df[\"%High_Edu\"].values, X).fit()\n",
    "model4.summary()\n",
    "\n",
    "model5 = sm.OLS(df[\"%Pop_Poverty\"].values, X).fit()\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-tests for difference in gini coefficients in areas where different crimes were committed.\n",
    "#Not all combinations of crime types were tested, since the results were nearly always significant.\n",
    "\n",
    "#Money versus drugs\n",
    "print(scipy.stats.ttest_ind(df[df.Offense_category_Money == 1][\"gini\"], \n",
    "                            df[df.Offense_category_Drugs == 1][\"gini\"]))\n",
    "\n",
    "#Money versus public\n",
    "print(scipy.stats.ttest_ind(df[df.Offense_category_Money == 1][\"gini\"], \n",
    "                            df[df.Offense_category_Public == 1][\"gini\"]))\n",
    "\n",
    "#Private versus death\n",
    "print(scipy.stats.ttest_ind(df[df.Offense_category_Private == 1][\"gini\"], \n",
    "                            df[df.Offense_category_Death == 1][\"gini\"]))\n",
    "\n",
    "#Drugs versus force\n",
    "print(scipy.stats.ttest_ind(df[df.Offense_category_Drugs == 1][\"gini\"], \n",
    "                            df[df.Offense_category_Force == 1][\"gini\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multivariable logistic regression using measures of inequality to predict the occurrences\n",
    "#Of each type of crime\n",
    "\n",
    "X = df[[\"gini\", \"income\", \"log_mean_prop_value\", \"%High_Income_HH\", \n",
    "       \"%Low_Edu\", \"%High_Edu\", \"%Pop_Poverty\"]]\n",
    "\n",
    "#Deaths\n",
    "logit_model = sm.Logit(df[\"Offense_category_Death\"], sm.add_constant(X)).fit()\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Drugs\n",
    "logit_model = sm.Logit(df[\"Offense_category_Drugs\"], sm.add_constant(X)).fit()\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Property\n",
    "logit_model = sm.Logit(df[\"Offense_category_Property\"], sm.add_constant(X)).fit()\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Public\n",
    "logit_model = sm.Logit(df[\"Offense_category_Public\"], sm.add_constant(X)).fit()\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Private\n",
    "logit_model = sm.Logit(df[\"Offense_category_Private\"], sm.add_constant(X)).fit()\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Force\n",
    "logit_model = sm.Logit(df[\"Offense_category_Force\"], sm.add_constant(X)).fit()\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Money\n",
    "logit_model = sm.Logit(df[\"Offense_category_Money\"], sm.add_constant(X)).fit()\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multivariable LASSO  logistic regression using measures of inequality to predict the occurrences\n",
    "#Of each type of crime\n",
    "\n",
    "X = df[[\"gini\", \"income\", \"log_mean_prop_value\", \"X.High_income_HH\", \n",
    "       \"X.Low_Edu\", \"X.High_Edu\", \"X.Pop_Poverty\"]]\n",
    "\n",
    "#Deaths\n",
    "logit_model = sm.Logit(df[\"Offense_category_Death\"], sm.add_constant(X)).fit_regularized(method = \"l1\", alpha = 1)\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Drugs\n",
    "logit_model = sm.Logit(df[\"Offense_category_Drugs\"], sm.add_constant(X)).fit_regularized(method = \"l1\", alpha = 1)\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Property\n",
    "logit_model = sm.Logit(df[\"Offense_category_Property\"], sm.add_constant(X)).fit_regularized(method = \"l1\", alpha = 1)\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Public\n",
    "logit_model = sm.Logit(df[\"Offense_category_Public\"], sm.add_constant(X)).fit_regularized(method = \"l1\", alpha = 1)\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Private\n",
    "logit_model = sm.Logit(df[\"Offense_category_Private\"], sm.add_constant(X)).fit_regularized(method = \"l1\", alpha = 1)\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Force\n",
    "logit_model = sm.Logit(df[\"Offense_category_Force\"], sm.add_constant(X)).fit_regularized(method = \"l1\", alpha = 1)\n",
    "print(logit_model.summary())\n",
    "\n",
    "#Money\n",
    "logit_model = sm.Logit(df[\"Offense_category_Money\"], sm.add_constant(X)).fit_regularized(method = \"l1\", alpha = 1)\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical linear regressions using crime types to predict measures of inequality\n",
    "\n",
    "df_crimes = df[[\"Offense_category_Death\", \"Offense_category_Drugs\", \"Offense_category_Force\", \"Offense_category_Money\", \"Offense_category_Private\", \"Offense_category_Public\"]]\n",
    "X = df_crimes.values\n",
    "\n",
    "#Gini coefficient\n",
    "model_gini = sm.OLS(df[\"gini\"].values, X).fit()\n",
    "print(model_gini.summary())\n",
    "\n",
    "#Percentage of people in high-income housing\n",
    "model_housing = sm.OLS(df[\"%High_Income_HH\"].values, X).fit()\n",
    "model_housing.summary()\n",
    "\n",
    "#Percentage of people with low education\n",
    "model_low = sm.OLS(df[\"%Low_Edu\"].values, X).fit()\n",
    "model_low.summary()\n",
    "\n",
    "#Percentage of people with high education\n",
    "model_high = sm.OLS(df[\"%High_Edu\"].values, X).fit()\n",
    "model_high.summary()\n",
    "\n",
    "#Percentage of people in poverty\n",
    "model_poverty = sm.OLS(df[\"%Pop_Poverty\"].values, X).fit()\n",
    "model_poverty.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network using all predictors to predict the type of crime\n",
    "df = pd.read_csv(\"final_dataset.csv\")\n",
    "df = df.drop(['Census Tracts', 'ZIP Code', 'AV_TOTAL', 'GROSS_AREA', 'mean_num_floor', 'mean_prop_value',\n",
    "        \"dist_trafficsignal\", \"dist_college\", \"dist_hubway\", \"dist_library\"], axis = 1)\n",
    "df = pd.get_dummies(df, columns = ['DAY_OF_WEE'])\n",
    "\n",
    "#Get rid of undesired categories\n",
    "df = df[df.Offense_category != \"No_offense\"]\n",
    "df = df[df.Offense_category != \"Other\"]\n",
    "df = df.dropna(axis=0, how=\"any\")\n",
    "df = df.drop(df[df.income  == 0].index)\n",
    "df = df.drop(df[df.gini  == 0].index)\n",
    "\n",
    "#Train-test split\n",
    "random_nums = np.random.rand(len(df)) < 0.8\n",
    "df_train = df[random_nums]\n",
    "df_test = df[~ random_nums]\n",
    "\n",
    "y_train = df_train[\"Offense_category\"]\n",
    "y_test = df_test[\"Offense_category\"]\n",
    "X_train = df_train.drop([\"Offense_category\"], axis = 1)\n",
    "X_test = df_test.drop([\"Offense_category\"], axis = 1)\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_test = min_max_scaler.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "\n",
    "# encode crime types as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "encoded_Y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = to_categorical(encoded_Y_test)\n",
    "\n",
    "encoder.fit(y_train)\n",
    "encoded_Y_train = encoder.transform(y_train)\n",
    "dummy_y_train = to_categorical(encoded_Y_train)\n",
    "\n",
    "X_train_dataset = X_train.values\n",
    "num_predictors = X_train.shape[1]\n",
    "X_train = X_train_dataset[:,0:num_predictors].astype(float)\n",
    "X_test_dataset = X_test.values\n",
    "X_test = X_test_dataset[:,0:num_predictors].astype(float)\n",
    "\n",
    "\n",
    "#Build neural network using Keras package of TensorFlow\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100,activation='relu',input_shape = (num_predictors,)))\n",
    "model.add(tf.keras.layers.Dense(200,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(7,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer= \"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, dummy_y_train, batch_size = 150, epochs = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get test accuracy of the neural network\n",
    "y_hat_test = model.predict(X_test)\n",
    "y_hat_test_discrete = y_hat_test\n",
    "length = y_hat_test.shape[1]\n",
    "for row_num in range(y_hat_test.shape[0]):\n",
    "    little_row = y_hat_test[row_num].tolist()\n",
    "    max_index = little_row.index(max(little_row))\n",
    "    little_list = np.zeros(length)\n",
    "    little_list[max_index] = 1\n",
    "    y_hat_test_discrete[row_num] = little_list\n",
    "    \n",
    "error = np.subtract(y_hat_test_discrete, dummy_y_test)\n",
    "error = error**2\n",
    "print(\"Test accuracy is: \", 1 - np.sum(error) / (2 * error.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataset \n",
    "crime = pd.read_csv('final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant predictors and create dummy columns\n",
    "crime = crime.drop(['Census Tracts','dist_library', 'AV_TOTAL', 'GROSS_AREA', 'mean_num_floor', 'mean_prop_value',\n",
    "        \"dist_trafficsignal\", \"dist_college\", \"dist_hubway\", 'ZIP Code' ], axis = 1)\n",
    "crime = pd.get_dummies(crime, columns=['DAY_OF_WEE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop crime categories that we are not going to predict\n",
    "crime = crime[crime.Offense_category != \"No_offense\"]\n",
    "crime = crime[crime.Offense_category != \"Other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test =train_test_split(crime.loc[:, crime.columns != 'Offense_category'], \n",
    "                                                         crime.Offense_category, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators = 100, max_depth = 18, max_features = 'auto') \n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest_train_score = random_forest.score(X_train, y_train)\n",
    "print(random_forest_train_score)\n",
    "random_forest_test_score = random_forest.score(X_test, y_test)\n",
    "print(random_forest_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a confusion matrix\n",
    "rf_test_predict = random_forest.predict(X_test)\n",
    "cm = confusion_matrix( y_test, rf_test_predict)\n",
    "# function to plot confusion matrix\n",
    "# from https://scikit-learn.org/0.18/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, classes= ['Death', 'Force', 'Public', 'Money', 'Private', 'Property', 'Drugs'],\n",
    "                      title='Random Forest Confusion Matrix')\n",
    "\n",
    "results = pd.DataFrame(columns = ['Feature', 'Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at feature importances for the random forest model \n",
    "importances = []\n",
    "features = []\n",
    "a = np.argsort(-random_forest.feature_importances_)\n",
    "for i in a:\n",
    "    print(X_train.columns[i])\n",
    "    features.append(X_train.columns[i])\n",
    "    print(random_forest.feature_importances_[i])\n",
    "    importances.append(random_forest.feature_importances_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Feature'] = features\n",
    "results['Importance'] = importances\n",
    "results['Importance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use a grid search with cross validation to find better hyperparameters that may improve our model\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 150, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 30, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_optimized = RandomizedSearchCV(estimator = random_forest, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_optimized.fit(X_train, y_train) # 1 - 1.5 hours to run \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimized_predict = rf_optimized.predict(X_train)\n",
    "accuracy_score(rf_optimized_predict, y_train)\n",
    "rf_optimized_predict_test = rf_optimized.predict(X_test)\n",
    "accuracy_score(rf_optimized_predict_test, y_test)\n",
    "# look at what parameters led to the best fit \n",
    "rf_optimized.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fit a model using xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgmodel = XGBClassifier()\n",
    "xgmodel.fit(X_train, y_train)\n",
    "xg_train = xgmodel.predict(X_train)\n",
    "accuracy_score(xg_train, y_train)\n",
    "xg_pred = xgmodel.predict(X_test)\n",
    "accuracy_score(xg_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calclations for Roc curves, approach from \n",
    "# http://benalexkeen.com/scoring-classifier-models-using-scikit-learn/\n",
    "# Use for original random forest model which has close to our best prediction accuracy\n",
    "y_predict_proba = random_forest.predict_proba(X_test)\n",
    "y_test_mod = []\n",
    "c = y_test.unique()\n",
    "b = y_test.tolist()\n",
    "for i in range(0, len(y_test)):\n",
    "    for j in range(0, len(c)):\n",
    "        if b[i] == c[j]:\n",
    "            y_test_mod.append(j)\n",
    "\n",
    "n_classes = 7\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "all_y_test_i = np.array([])\n",
    "all_y_predict_proba = np.array([])\n",
    "for i in range(n_classes):\n",
    "    y_test_i = map(lambda x: 1 if x == i else 0, y_test)\n",
    "    y_test_i = [0 for i in range(0, len(y_test))]\n",
    "    for j in range(0, len(y_test)):\n",
    "        if y_test_mod[j] == i:\n",
    "            y_test_i[j] = 1\n",
    "        else:\n",
    "             y_test_i[j] = 0\n",
    "            \n",
    "    all_y_test_i = np.concatenate([all_y_test_i, y_test_i])\n",
    "    all_y_predict_proba = np.concatenate([all_y_predict_proba, y_predict_proba[:, i]])\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_i, y_predict_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"average\"], tpr[\"average\"], _ = roc_curve(all_y_test_i, all_y_predict_proba)\n",
    "roc_auc[\"average\"] = auc(fpr[\"average\"], tpr[\"average\"])\n",
    "\n",
    "\n",
    "# Plot average ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"average\"], tpr[\"average\"],\n",
    "         label='Average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"average\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "# Plot each individual ROC curve\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"upper left\", prop={'size': 7})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
